# Linear Regression

Linear regression models the relationship between a dependent variable and one or more independent variables using a linear equation.

---

## üìÇ 1. Types of Linear Regression

```mermaid
graph LR
    A["Linear Regression"] --> B["Simple Linear"]
    A --> C["Multiple Linear"]
    
    B --- B1["1 Input (X) + 1 Target (Y)"]
    C --- C1[">1 Input (Xn) + 1 Target (Y)"]
    
    B1 --- B2["Y = Œ≤0 + Œ≤1X + Œµ"]
    C1 --- C2["Y = Œ≤0 + Œ≤1X1 + ... + Œ≤nXn + Œµ"]
```

---

## üõ°Ô∏è 2. The 5 Key Assumptions

Before training, your data should meet these criteria:

```mermaid
graph TD
    A["Assumptions"] --> B["Linearity"]
    A --> C["Independence"]
    A --> D["Homoscedasticity"]
    A --> E["Normality"]
    A --> F["No Multicollinearity"]

    B --- B1["Relationship is a straight line"]
    C --- C1["Residuals are independent"]
    D --- D1["Constant variance of errors"]
    E --- E1["Errors follow Normal Distribution"]
    F --- F1["Inputs are not highly correlated"]
```

---

## ‚öôÔ∏è 3. Mathematical Pipeline

The flow from data to optimized model:

```mermaid
graph TD
    Data["Raw Data (X, Y)"] --> Hypo["Hypothesis: hŒ∏(x) = Œ∏0 + Œ∏1x"]
    Hypo --> Cost["Cost Function (MSE): J(Œ∏)"]
    Cost --> Opt["Optimizer: Gradient Descent"]
    Opt --> Update["Update Params (Œ∏)"]
    Update -- "Minimize J(Œ∏)" --> Hypo
    Update --> Final["Optimized Model"]
```

---

[‚¨ÖÔ∏è Back to Regression Overview](README.md) | [‚¨ÖÔ∏è Back to Home](../README.md)
