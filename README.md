# üìò Machine Learning ‚Äì Structured Notes

---

## üìö Syllabus Overview

1. **Introduction**
2. **Regression**
   - Linear Regression
   - Logistic Regression
3. **Decision Tree**
4. **Ensemble Learning**
5. **Bayesian Learning**
6. **Support Vector Machine (SVM)**
7. **Association Rules**
8. **Clustering**

---

## 1Ô∏è‚É£ Introduction

<details>
<summary><strong>Click to expand</strong></summary>

- What is Machine Learning?
- Types of ML
- Applications
- ML pipeline

</details>

---

## 2Ô∏è‚É£ Regression

### 2.1 Linear Regression ‚úÖ

<details open>
<summary><strong>Click to expand</strong></summary>

**Problem Type:** Predict continuous values  

**Model:**
\[
\hat{y} = \theta_0 + \theta_1 x
\]

**Cost Function (MSE):**
\[
MSE = \frac{1}{n}\sum (y - \hat{y})^2
\]

**Intuition:**  
Draw the best straight line by minimizing error.

</details>

---

### 2.2 Logistic Regression

<details>
<summary><strong>Click to expand</strong></summary>

- Classification problem  
- Uses sigmoid function  
- Outputs probability  

</details>

---

## 3Ô∏è‚É£ Decision Tree

<details>
<summary><strong>Click to expand</strong></summary>

- Tree-based model  
- Gini / Entropy  
- Recursive splits  

</details>

---

## 4Ô∏è‚É£ Ensemble Learning

<details>
<summary><strong>Click to expand</strong></summary>

- Bagging  
- Boosting  
- Random Forest  

</details>

---

## 5Ô∏è‚É£ Bayesian Learning

<details>
<summary><strong>Click to expand</strong></summary>

- Bayes Theorem  
- Naive Bayes  

</details>

---

## 6Ô∏è‚É£ Support Vector Machine (SVM)

<details>
<summary><strong>Click to expand</strong></summary>

- Max-margin classifier  
- Kernel trick  

</details>

---

## 7Ô∏è‚É£ Association Rules

<details>
<summary><strong>Click to expand</strong></summary>

- Support  
- Confidence  
- Lift  

</details>

---

## 8Ô∏è‚É£ Clustering

<details>
<summary><strong>Click to expand</strong></summary>

- K-Means  
- Hierarchical  
- DBSCAN  

</details>
